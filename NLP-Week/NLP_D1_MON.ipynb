{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwukv0J9B0a_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization:\n",
        "             Parsing of sentences.\n",
        "             "
      ],
      "metadata": {
        "id": "fPkxEy31CBTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHp9K8fICaUQ",
        "outputId": "f7e141c6-103f-4e18-b943-3924393ba71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download() # punkt, stopwords, wordnet, averaged_perceptron_tagger, maxent_ne_chunker, words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FpaiyGxCuQW",
        "outputId": "51222577-5aa6-40fe-920d-d83aa8d19ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> punkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package punkt to /root/nltk_data...\n",
            "      Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> wordnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> averaged_perceptron_tagger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package averaged_perceptron_tagger to\n",
            "        /root/nltk_data...\n",
            "      Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> maxent_ne_chunker\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "      Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package words to /root/nltk_data...\n",
            "      Package words is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "gS-6l9pRFpgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "# Training data\n",
        "sentences = [\n",
        "    \"I love cats\",\n",
        "    \"Cats are adorable\",\n",
        "    \"Dogs are loyal\",\n",
        "    \"I have a dog\",\n",
        "    \"Cats and dogs are friends\",\n",
        "    \"I enjoy playing with cats\",\n",
        "    \"Dogs love to fetch\",\n",
        "    \"I prefer cats over dogs\",\n",
        "    \"Cats make great companions\",\n",
        "    \"Dogs are man's best friend\",\n",
        "\n",
        "]\n",
        "\n",
        "# Function to generate n-grams from sentences\n",
        "def generate_ngrams(sentences, n):\n",
        "    ngrams = defaultdict(list)\n",
        "    for sentence in sentences:\n",
        "        words = sentence.lower().split()\n",
        "        for i in range(len(words) - n + 1):\n",
        "            ngram = ' '.join(words[i:i+n-1])\n",
        "            next_word = words[i+n-1]\n",
        "            ngrams[ngram].append(next_word)\n",
        "    return ngrams\n",
        "\n",
        "# Generate 2-gram and 3-gram models\n",
        "ngram_2 = generate_ngrams(sentences, 2)\n",
        "ngram_3 = generate_ngrams(sentences, 3)\n",
        "ngram_4 = generate_ngrams(sentences, 4)\n",
        "\n",
        "# Predict the next word based on 2-gram\n",
        "seed_2 = random.choice(list(ngram_2.keys()))\n",
        "next_word_2 = random.choice(ngram_2[seed_2])\n",
        "\n",
        "# Predict the next word based on 3-gram\n",
        "seed_3 = random.choice(list(ngram_3.keys()))\n",
        "next_word_3 = random.choice(ngram_3[seed_3])\n",
        "\n",
        "# Predict the next word based on 4-gram\n",
        "seed_4 = random.choice(list(ngram_4.keys()))\n",
        "next_word_4 = random.choice(ngram_4[seed_4])\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Using 2-gram model:\")\n",
        "print(f\"Seed: '{seed_2}', Predicted Next Word: '{next_word_2}'\")\n",
        "print()\n",
        "print(\"Using 3-gram model:\")\n",
        "print(f\"Seed: '{seed_3}', Predicted Next Word: '{next_word_3}'\")\n",
        "print()\n",
        "print(\"Using 4-gram model:\")\n",
        "print(f\"Seed: '{seed_4}', Predicted Next Word: '{next_word_4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aynpn1rKJfS",
        "outputId": "c8ec9901-5227-45af-b577-de092873e0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 2-gram model:\n",
            "Seed: 'enjoy', Predicted Next Word: 'playing'\n",
            "\n",
            "Using 3-gram model:\n",
            "Seed: 'enjoy playing', Predicted Next Word: 'with'\n",
            "\n",
            "Using 4-gram model:\n",
            "Seed: 'dogs are man's', Predicted Next Word: 'best'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9i6LlcdK00T",
        "outputId": "6acc389f-f41d-414f-d5e8-eafc620f9b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'i': ['love', 'have', 'enjoy', 'prefer'],\n",
              "             'love': ['cats', 'to'],\n",
              "             'cats': ['are', 'and', 'over', 'make'],\n",
              "             'are': ['adorable', 'loyal', 'friends', \"man's\"],\n",
              "             'dogs': ['are', 'are', 'love', 'are'],\n",
              "             'have': ['a'],\n",
              "             'a': ['dog'],\n",
              "             'and': ['dogs'],\n",
              "             'enjoy': ['playing'],\n",
              "             'playing': ['with'],\n",
              "             'with': ['cats'],\n",
              "             'to': ['fetch'],\n",
              "             'prefer': ['cats'],\n",
              "             'over': ['dogs'],\n",
              "             'make': ['great'],\n",
              "             'great': ['companions'],\n",
              "             \"man's\": ['best'],\n",
              "             'best': ['friend']})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d6EeudcK9i-",
        "outputId": "5ad86af2-4c39-40c5-acfa-b24573d67c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'i love': ['cats'],\n",
              "             'cats are': ['adorable'],\n",
              "             'dogs are': ['loyal', 'friends', \"man's\"],\n",
              "             'i have': ['a'],\n",
              "             'have a': ['dog'],\n",
              "             'cats and': ['dogs'],\n",
              "             'and dogs': ['are'],\n",
              "             'i enjoy': ['playing'],\n",
              "             'enjoy playing': ['with'],\n",
              "             'playing with': ['cats'],\n",
              "             'dogs love': ['to'],\n",
              "             'love to': ['fetch'],\n",
              "             'i prefer': ['cats'],\n",
              "             'prefer cats': ['over'],\n",
              "             'cats over': ['dogs'],\n",
              "             'cats make': ['great'],\n",
              "             'make great': ['companions'],\n",
              "             \"are man's\": ['best'],\n",
              "             \"man's best\": ['friend']})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_4"
      ],
      "metadata": {
        "id": "PnjdAUhQMD7A",
        "outputId": "05aa48f5-aee3-433a-9156-b35ec89d322a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'i have a': ['dog'],\n",
              "             'cats and dogs': ['are'],\n",
              "             'and dogs are': ['friends'],\n",
              "             'i enjoy playing': ['with'],\n",
              "             'enjoy playing with': ['cats'],\n",
              "             'dogs love to': ['fetch'],\n",
              "             'i prefer cats': ['over'],\n",
              "             'prefer cats over': ['dogs'],\n",
              "             'cats make great': ['companions'],\n",
              "             \"dogs are man's\": ['best'],\n",
              "             \"are man's best\": ['friend']})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}